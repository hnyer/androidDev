# 音视频相关代码

## SurfaceView 绘制图片
```text
SurfaceView surfaceView = findViewById(R.id.surface);
surfaceView.getHolder().addCallback(new SurfaceHolder.Callback() {
    @Override
    public void surfaceCreated(SurfaceHolder surfaceHolder) {
        Canvas canvas = surfaceHolder.lockCanvas();
        canvas.drawBitmap(bitmap, 0, 0, paint);
        surfaceHolder.unlockCanvasAndPost(canvas);
    }

    @Override
    public void surfaceChanged(SurfaceHolder surfaceHolder, int i, int i1, int i2) {   }

    @Override
    public void surfaceDestroyed(SurfaceHolder surfaceHolder) {  }
});
```

## AudioRecord 采集并保存PCM
```text
   /**
    * 采样率，现在能够保证在所有设备上使用的采样率是44100Hz,
    * 但是其他的采样率（22050, 16000, 11025）在一些设备上也可以使用。
    */
   public static final int SAMPLE_RATE_INHZ = 44100;

   /**
    * 声道数。CHANNEL_IN_MONO and CHANNEL_IN_STEREO.
    * 其中CHANNEL_IN_MONO是可以保证在所有设备能够使用的。
    */
   public static final int CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO;
   /**
    * 返回的音频数据的格式。 ENCODING_PCM_8BIT, ENCODING_PCM_16BIT, and ENCODING_PCM_FLOAT.
    */
   public static final int AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT;
   private AudioRecord audioRecord = null;
   private boolean isRecording = false;

   public void onstart(View view) {
       // 一次读取多少内容
       final int minBufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE_INHZ, CHANNEL_CONFIG, AUDIO_FORMAT);
       audioRecord = new AudioRecord(MediaRecorder.AudioSource.MIC, SAMPLE_RATE_INHZ,  CHANNEL_CONFIG, AUDIO_FORMAT, minBufferSize);
       final byte data[] = new byte[minBufferSize];

       audioRecord.startRecording();
       isRecording = true;

       new Thread(new Runnable() {
           @SuppressWarnings("AlibabaAvoidManuallyCreateThread")
           @Override
           public void run() {
               FileOutputStream os = null;
               try {
                   File file = new File(Environment.getExternalStorageDirectory(), "testttttttt.pcm");
                   os = new FileOutputStream(file);
               } catch (FileNotFoundException e) {
                   e.printStackTrace();
               }

               if (null != os) {
                   while (isRecording) {
                       Log.i("aivin" ,"正在录制") ;
                       int read = audioRecord.read(data, 0, minBufferSize);
                       // 如果读取音频数据没有出现错误，就将数据写入到文件
                       if (AudioRecord.ERROR_INVALID_OPERATION != read) {
                           try {
                               os.write(data);
                           } catch (IOException e) {
                               e.printStackTrace();
                           }
                       }
                   }
                   try {
                       os.close();
                   } catch (IOException e) {
                       e.printStackTrace();
                   }
               }
           }
       }).start();
   }
```

## AudioTrack 播放PCM

```text
AudioTrack有两种数据加载模式
MODE_STREAM ：通过write一次次把音频数据写到AudioTrack中。每次都需要把数据从用户提供的Buffer中拷贝到AudioTrack内部的Buffer中，这在一定程度上会使引入延时。适合大文件。

MODE_STATIC ：把所有数据通过一次write调用传递到AudioTrack中的内部缓冲区，后续就不必再传递数据了。
这种模式适用于像铃声这种内存占用量较小，延时要求较高的文件。
```

```text
 /**
  * 采样率，现在能够保证在所有设备上使用的采样率是44100Hz,
  * 但是其他的采样率（22050, 16000, 11025）在一些设备上也可以使用。
  */
 public static final int SAMPLE_RATE_INHZ = 44100;
 /**
  * 返回的音频数据的格式。 ENCODING_PCM_8BIT, ENCODING_PCM_16BIT, and ENCODING_PCM_FLOAT.
  */
 public static final int AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT;

 /**
  * 播放，使用stream模式
  */
 public void onplay(View view) {
     final int minBufferSize = AudioTrack.getMinBufferSize(SAMPLE_RATE_INHZ, AudioFormat.CHANNEL_OUT_MONO, AUDIO_FORMAT);
     final  AudioTrack   audioTrack = new AudioTrack(
             new AudioAttributes.Builder()
                     .setUsage(AudioAttributes.USAGE_MEDIA)
                     .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                     .build(),
             new AudioFormat.Builder().setSampleRate(SAMPLE_RATE_INHZ)
                     .setEncoding(AUDIO_FORMAT)
                     .setChannelMask(AudioFormat.CHANNEL_OUT_MONO)
                     .build(),
             minBufferSize,
             AudioTrack.MODE_STREAM,
             AudioManager.AUDIO_SESSION_ID_GENERATE);
     audioTrack.play();

     File file = new File(Environment.getExternalStorageDirectory(), "testttttttt.pcm");
     try {
         final FileInputStream  fileInputStream = new FileInputStream(file);
         new Thread(new Runnable() {
             @Override
             public void run() {
                 try {
                     byte[] tempBuffer = new byte[minBufferSize];
                     while (fileInputStream.available() > 0) {
                         int readCount = fileInputStream.read(tempBuffer);
                         if (readCount == AudioTrack.ERROR_INVALID_OPERATION ||  readCount == AudioTrack.ERROR_BAD_VALUE) {
                             continue;
                         }
                         if (readCount != 0 && readCount != -1) {
                             audioTrack.write(tempBuffer, 0, readCount);
                         }
                     }
                 } catch (IOException e) {
                     e.printStackTrace();
                 }
             }
         }).start();

     } catch (IOException e) {
         e.printStackTrace();
     }
 }
```

## pcm转 wav
在pcm数据前加上wav文件头即可
```text
https://www.jianshu.com/p/f7863638acbe
```

## wav 转 pcm
去掉文件头即可
```text
https://www.jianshu.com/p/3f80fb907bd5
```


##  Camera2 API 预览并获得YUV数据
```text
public class GetCameraActivity extends Activity {
    private Context context;
    private TextureView mPreviewView;
    private Handler mHandler;
    private Size mPreviewSize;
    private static final SparseIntArray ORIENTATIONS = new SparseIntArray();
    public ImageReader mImageReader;
    private CaptureRequest.Builder mCaptureRequest;
    /**
     *  0-->后置相机  1---> 前置相机
     */
    private String mCameraId = "1";


    @Override
    protected void onCreate(@Nullable Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_getcamera);
        context = this;

        ORIENTATIONS.append(Surface.ROTATION_0, 90);
        ORIENTATIONS.append(Surface.ROTATION_90, 0);
        ORIENTATIONS.append(Surface.ROTATION_180, 270);
        ORIENTATIONS.append(Surface.ROTATION_270, 180);

        mPreviewView = findViewById(R.id.textureview);
        mPreviewView.setSurfaceTextureListener(surfaceTextureListener);

        HandlerThread mThreadHandler = new HandlerThread("CAMERA2");
        mThreadHandler.start();
        mHandler = new Handler(mThreadHandler.getLooper());

    }


    private void startPreview(CameraDevice camera) throws CameraAccessException {
        try {
            // 请求预览
            mCaptureRequest = camera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        } catch (CameraAccessException e) {
            e.printStackTrace();
        }

        // 自动对焦
        mCaptureRequest.set(CaptureRequest.CONTROL_AF_MODE,  CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE);

        //设置方向
        CameraManager manager = (CameraManager) getSystemService(Context.CAMERA_SERVICE);
        CameraCharacteristics characteristics = manager.getCameraCharacteristics(mCameraId);
        //摄像头传感器方向
        int mSensorOrientation = characteristics.get(CameraCharacteristics.SENSOR_ORIENTATION);
        // 获取设备方向
        int rotation = getWindowManager().getDefaultDisplay().getRotation();
        // 根据设备方向计算设置摄像头的方向
        int value = (ORIENTATIONS.get(rotation) + mSensorOrientation + 270) % 360;
        mCaptureRequest.set(CaptureRequest.JPEG_ORIENTATION, value);

        // yuv数据回调
        mImageReader = ImageReader.newInstance(mPreviewSize.getWidth(), mPreviewSize.getHeight(), ImageFormat.YUV_420_888, 2);
        mImageReader.setOnImageAvailableListener(mOnImageAvailableListener, mHandler);

        // 使预览和yuv回调生效
        SurfaceTexture texture = mPreviewView.getSurfaceTexture();
        texture.setDefaultBufferSize(mPreviewSize.getWidth(), mPreviewSize.getHeight());
        Surface surface = new Surface(texture);
        mCaptureRequest.addTarget(surface);
        mCaptureRequest.addTarget(mImageReader.getSurface());

        // 创建相机捕获会话，第一个参数是捕获数据的输出Surface列表，
        // 第二个参数是CameraCaptureSession的状态回调接口，当它创建好后会回调 onConfigured 方法
        // 第三个参数用来确定Callback在哪个线程执行，为null的话就在当前线程执行
        camera.createCaptureSession(Arrays.asList(surface, mImageReader.getSurface()), mSessionStateCallback, mHandler);
    }

    /**
     * textureView 状态 回调
     */
    TextureView.SurfaceTextureListener surfaceTextureListener = new TextureView.SurfaceTextureListener() {
        @Override
        public void onSurfaceTextureAvailable(SurfaceTexture surface, int width, int height) {
            try {
                CameraManager cameraManager = (CameraManager) context.getSystemService(Context.CAMERA_SERVICE);
                //获得指定摄像头的特征，支持的参数
                CameraCharacteristics characteristics = cameraManager.getCameraCharacteristics(mCameraId);
                StreamConfigurationMap streamConfigurationMap = characteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
                //摄像头支持的预览Size数组
                List list = Arrays.asList(streamConfigurationMap.getOutputSizes(ImageFormat.YUV_420_888));

                Size size4 = new Size(640, 480);
                if (!list.contains(size4)) {
                    // 根据TextureView的尺寸设置预览尺寸
                    mPreviewSize = streamConfigurationMap.getOutputSizes(SurfaceTexture.class)[0];
                } else {
                    mPreviewSize = size4;
                }

                for (String cameraId : cameraManager.getCameraIdList()) {
                    CameraCharacteristics characteristic
                            = cameraManager.getCameraCharacteristics(cameraId);
                    Integer facing = characteristic.get(CameraCharacteristics.LENS_FACING);
                    if (facing != null && facing == CameraCharacteristics.LENS_FACING_BACK) {
                        mCameraId = cameraId;
                        break;
                    }
                }
                //打开相机
                if (ActivityCompat.checkSelfPermission(context, Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) {
                    return;
                }
                cameraManager.openCamera(mCameraId, mCameraDeviceStateCallback, mHandler);
            } catch (CameraAccessException e) {
                e.printStackTrace();
            }
        }

        @Override
        public void onSurfaceTextureSizeChanged(SurfaceTexture surface, int width, int height) {
        }

        @Override
        public boolean onSurfaceTextureDestroyed(SurfaceTexture surface) {
            return false;
        }

        @Override
        public void onSurfaceTextureUpdated(SurfaceTexture surface) {  }
    };


    /**
     * 相机打开状态回调
     */
    private CameraDevice.StateCallback mCameraDeviceStateCallback = new CameraDevice.StateCallback() {

        @Override
        public void onOpened(CameraDevice camera) {
            try {
                startPreview(camera);
            } catch (CameraAccessException e) {
                e.printStackTrace();
            }
        }

        @Override
        public void onDisconnected(CameraDevice camera) {
            camera.close();
        }

        @Override
        public void onError(CameraDevice camera, int error) {
            camera.close();
        }
    };

    /**
     * 数据回调接口
     */
    private ImageReader.OnImageAvailableListener mOnImageAvailableListener = new ImageReader.OnImageAvailableListener() {
        @Override
        public void onImageAvailable(ImageReader reader) {
            Image image = reader.acquireNextImage();
            //YUV_420_888格式 ---->获取到的三个通道 getPlanes 分别对应YUV
            Image.Plane[] planes = image.getPlanes();
            ByteBuffer byteBufferY = planes[0].getBuffer() ;
            byte[] dataY = new byte[ byteBufferY.remaining()];
            byteBufferY.get(dataY) ;
            Log.i("aivin" ,"收到数据回调 Y分量： " + dataY.length);
            image.close();
        }
    };

    /**
     * 相机会话状态接口
     */
    private CameraCaptureSession.StateCallback mSessionStateCallback = new CameraCaptureSession.StateCallback() {

        @Override
        public void onConfigured(CameraCaptureSession session) {
            try {
                //设置反复捕获数据的请求，这样预览界面就会一直有数据显示
                session.setRepeatingRequest(mCaptureRequest.build(), null, mHandler);
            } catch (CameraAccessException e) {
                e.printStackTrace();
            }
        }

        @Override
        public void onConfigureFailed(CameraCaptureSession session) {      }
    };
}
```


## MediaMuxer 分离 音频、视频
```text
private void extractorVideo() throws IOException {
       String inputFilePath = Environment.getExternalStorageDirectory().getPath()+"/input.mp4" ;
       String outputVideoFilePath = Environment.getExternalStorageDirectory().getPath()+"/output.mp4" ;
       MediaMuxer mMediaMuxer =null;
       MediaExtractor mMediaExtractor = new MediaExtractor();
       mMediaExtractor.setDataSource(inputFilePath);

       int mVideoTrackIndex = -1;
       int framerate = 0;
       for (int i = 0; i < mMediaExtractor.getTrackCount(); i++) {
           MediaFormat format = mMediaExtractor.getTrackFormat(i);
           String mime = format.getString(MediaFormat.KEY_MIME);
           if (mime.startsWith("video/")) {
               framerate = format.getInteger(MediaFormat.KEY_FRAME_RATE);
               // 选择视频通道
               mMediaExtractor.selectTrack(i);
               mMediaMuxer = new MediaMuxer(outputVideoFilePath, MediaMuxer.OutputFormat.MUXER_OUTPUT_MPEG_4);
               mVideoTrackIndex = mMediaMuxer.addTrack(format);
               break;
           }
       }

       MediaCodec.BufferInfo info = new MediaCodec.BufferInfo();
       info.presentationTimeUs = 0;
       ByteBuffer buffer = ByteBuffer.allocate(1024 * 1024);
       int dataSize ;
       mMediaMuxer.start();
       while ( (dataSize = mMediaExtractor.readSampleData(buffer, 0)) > 0) {
           info.offset = 0;
           info.size = dataSize;
           info.flags = MediaCodec.BUFFER_FLAG_SYNC_FRAME;
           info.presentationTimeUs += 1000 * 1000 / framerate;
           mMediaMuxer.writeSampleData(mVideoTrackIndex, buffer, info);
           // 继续读取下一帧数据
           mMediaExtractor.advance();
       }
       mMediaExtractor.release();
       mMediaMuxer.stop();
       mMediaMuxer.release();
   }

private void extractorAudio() throws IOException {
      String inputFilePath = Environment.getExternalStorageDirectory().getPath()+"/input.mp4" ;
      String outputVideoFilePath = Environment.getExternalStorageDirectory().getPath()+"/output.mp3" ;
      MediaMuxer mMediaMuxer =null;
      MediaExtractor mMediaExtractor = new MediaExtractor();
      mMediaExtractor.setDataSource(inputFilePath);

      int mVideoTrackIndex = -1;
      int framerate = 0;
      for (int i = 0; i < mMediaExtractor.getTrackCount(); i++) {
          MediaFormat format = mMediaExtractor.getTrackFormat(i);
          String mime = format.getString(MediaFormat.KEY_MIME);
          if (mime.startsWith("audio/")) {
              // 选择视频通道
              mMediaExtractor.selectTrack(i);
              mMediaMuxer = new MediaMuxer(outputVideoFilePath, MediaMuxer.OutputFormat.MUXER_OUTPUT_MPEG_4);
              mVideoTrackIndex = mMediaMuxer.addTrack(format);
          }else if(mime.startsWith("video/")){
              framerate = format.getInteger(MediaFormat.KEY_FRAME_RATE);
          }
      }

      MediaCodec.BufferInfo info = new MediaCodec.BufferInfo();
      info.presentationTimeUs = 0;
      ByteBuffer buffer = ByteBuffer.allocate(1024 * 1024);
      int dataSize ;
      mMediaMuxer.start();
      while ( (dataSize = mMediaExtractor.readSampleData(buffer, 0)) > 0) {
          info.offset = 0;
          info.size = dataSize;
          info.flags = MediaCodec.BUFFER_FLAG_SYNC_FRAME;
          info.presentationTimeUs += 1000 * 1000 / framerate;
          mMediaMuxer.writeSampleData(mVideoTrackIndex, buffer, info);
          // 继续读取下一帧数据
          mMediaExtractor.advance();
      }
      mMediaExtractor.release();
      mMediaMuxer.stop();
      mMediaMuxer.release();
  }
```


## MediaMuxer 将音频、视频混合
```text
private void mixVedioAndAudio() {
    String inputVedioPath = Environment.getExternalStorageDirectory().getPath()+"/input.mp4" ;
    String inputAudioPath = Environment.getExternalStorageDirectory().getPath()+"/input.mp3" ;
    String outputVideoFilePath = Environment.getExternalStorageDirectory().getPath()+"/output.mp4" ;

    MediaExtractor videoExtractor ;
    MediaExtractor audioExtractor ;
    MediaMuxer mixMediaMuxer ;

    int framerate = 0;
    try {
        videoExtractor = new MediaExtractor();
        videoExtractor.setDataSource(inputVedioPath);
        int videoIndex = -1;
        MediaFormat videoTrackFormat = null;
        int trackCount = videoExtractor.getTrackCount();
        for (int i = 0; i < trackCount; i++) {
            videoTrackFormat = videoExtractor.getTrackFormat(i);
            if (videoTrackFormat.getString(MediaFormat.KEY_MIME).startsWith("video/")) {
                videoIndex = i;
                framerate = videoTrackFormat.getInteger(MediaFormat.KEY_FRAME_RATE);
            }
        }

        audioExtractor = new MediaExtractor();
        audioExtractor.setDataSource(inputAudioPath);
        int audioIndex = -1;
        MediaFormat audioTrackFormat = null;
        trackCount = audioExtractor.getTrackCount();
        for (int i = 0; i < trackCount; i++) {
            audioTrackFormat = audioExtractor.getTrackFormat(i);
            if (audioTrackFormat.getString(MediaFormat.KEY_MIME).startsWith("audio/")) {
                audioIndex = i;
            }
        }

        videoExtractor.selectTrack(videoIndex);
        audioExtractor.selectTrack(audioIndex);

        mixMediaMuxer = new MediaMuxer(outputVideoFilePath, MediaMuxer.OutputFormat.MUXER_OUTPUT_MPEG_4);
        int videoTrackIndex = mixMediaMuxer.addTrack(videoTrackFormat);
        int audioTrackIndex = mixMediaMuxer.addTrack(audioTrackFormat);
        mixMediaMuxer.start();

        ByteBuffer byteBuffer = ByteBuffer.allocate(1024 * 1024);
        MediaCodec.BufferInfo videoBufferInfo = new MediaCodec.BufferInfo();
        MediaCodec.BufferInfo audioBufferInfo = new MediaCodec.BufferInfo();
        while (true) {
            int data = videoExtractor.readSampleData(byteBuffer, 0);
            if (data < 0) {
                break;
            }
            videoBufferInfo.size = data;
            videoBufferInfo.presentationTimeUs +=  1000 *1000 /framerate;
            videoBufferInfo.offset = 0;
            videoBufferInfo.flags = MediaCodec.BUFFER_FLAG_SYNC_FRAME;

            mixMediaMuxer.writeSampleData(videoTrackIndex, byteBuffer, videoBufferInfo);
            videoExtractor.advance();
        }

        while (true) {
            int data = audioExtractor.readSampleData(byteBuffer, 0);
            if (data < 0) {
                break;
            }
            audioBufferInfo.size = data;
            audioBufferInfo.presentationTimeUs +=  1000 *1000 /framerate;
            audioBufferInfo.offset = 0;
            audioBufferInfo.flags = MediaCodec.BUFFER_FLAG_SYNC_FRAME;

            mixMediaMuxer.writeSampleData(audioTrackIndex, byteBuffer, audioBufferInfo);
            audioExtractor.advance();
        }

        mixMediaMuxer.stop();
        mixMediaMuxer.release();
        videoExtractor.release();
        audioExtractor.release();
    } catch (IOException e) {
        e.printStackTrace();
    }
}
```

## MediaCodec 常用 API
```text
return the output image, or null if  ... or if the codec  was configured with an output surface.
mMeidaCodec.getOutputImage(outputBufferIndex) ;

// 注意： 如果配置了 surfaceview， 数据就被消耗掉了 ，就拿不到解码后的数据了 。
mMeidaCodec.configure(mediaFormat, mSurfaceView.getHolder().getSurface(), null, 0);
```


##  MediaCodec + camera + SurfaceView  预览并保存 H264 文件
java实现
```text
https://gitee.com/hnyer/codeSnippet/tree/master/onlyh264
```


##  camera + SurfaceView + AudioRecord+ MediaCodec+  MediaMuxer 预览并生成 mp4文件
java实现
```text
https://gitee.com/hnyer/codeSnippet/tree/master/muxer
```



#  常用ffmpeg代码片段
## 导入头文件
```text
extern "C"
{
#include <libavcodec/avcodec.h>
}
```

## 遍历 AVCodec
```text
av_register_all();
AVCodec * codec= av_codec_next(NULL) ;
while(codec !=NULL)
{
    LOGI("信息 codec->type =%s" , codec->name) ;
    // 获取下一个
    codec = codec->next ;
}
```


## 配置信息
```text
const char* configuration  = avcodec_configuration() ;
LOGI("配置信息configuration =%s" , configuration) ;
```

## 遍历AVInputFormat
```text
av_register_all();
char * info = (char * )malloc(40000);
memset(info,0,40000);
AVInputFormat *if_temp = av_iformat_next(NULL );
while(if_temp!=NULL){
    sprintf(info, "===%s   ", if_temp->name );
    LOGI("信息 AVInputFormat =%s" , info ) ;
    if_temp=if_temp->next ;
}
```


## 遍历AVOutputFormat
```text
av_register_all();
char *info=(char * )malloc(40000);
memset(info,0,40000);
AVOutputFormat *of_temp  = av_oformat_next(NULL);
while(of_temp!=NULL){
    sprintf(info, "===%s   ", of_temp->name);
    LOGI("信息 AVOutputFormat =%s" , info) ;
    of_temp=of_temp->next;
}
```


## 遍历 AVFilter
```text
avfilter_register_all();
char *info=(char * )malloc(40000);
memset(info,0,40000);

AVFilter * f_temp = (AVFilter * )avfilter_next(NULL);
while (f_temp != NULL){
    sprintf(info, "%s",  f_temp->name);
    LOGI("信息 AVFilter =%s" , info) ;
    f_temp=f_temp->next;
}
```






## mp3 转 aac
```text
// 转换命令
ffmpeg -i xxx.mp3  xxx.aac

JNIEXPORT jint xxxxxxxxxxxMp3ToAAC
(JNIEnv * env, jclass obj, jobjectArray commands)
{
    int argc = ( * env)->GetArrayLength(env, commands);
    char **argv = (char * * )malloc(argc * sizeof(char* ));
    int i;
    int result;
    for (i = 0; i < argc; i++)
    {
        jstring jstr = (jstring) (* env)->GetObjectArrayElement(env, commands, i);
        char* temp = (char* ) (* env)->GetStringUTFChars(env, jstr, 0);
        argv[i] = malloc(1024);
        strcpy(argv[i], temp);
        (*env)->ReleaseStringUTFChars(env, jstr, temp);
    }
    //执行ffmpeg命令 ,  将源码中的 main() 改成run()
    result =  run(argc, argv);
    //释放内存
    for (i = 0; i < argc; i++)
    {
        free(argv[i]);
    }
    free(argv);
    return result;
}
```


## 音频解码 + 播放
native ffmpeg 实现解码 ， java层的 AudioTrack 实现播放
```text
#define MAX_AUDIO_FRAME_SIZE 48000 * 4
JNIEXPORT void JNICALL Java_xxxx_play
  (JNIEnv *env, jobject jthiz, jstring input_jstr){
	const char* input_cstr = (*env)->GetStringUTFChars(env,input_jstr,NULL);
	//注册组件
	av_register_all();
	AVFormatContext *pFormatCtx = avformat_alloc_context();
	//打开音频文件
	if(avformat_open_input(&pFormatCtx,input_cstr,NULL,NULL) != 0)
	{
		return;
	}
	//获取输入文件信息
	if(avformat_find_stream_info(pFormatCtx,NULL) < 0){
		return;
	}
	//获取音频流索引位置
	int  audio_stream_idx = -1;
	for(int i=0; i < pFormatCtx->nb_streams;i++)
	{
		if(pFormatCtx->streams[i]->codec->codec_type == AVMEDIA_TYPE_AUDIO)
		{
			audio_stream_idx = i;
			break;
		}
	}

	//获取音频解码器
	AVCodecContext *codecCtx = pFormatCtx->streams[audio_stream_idx]->codec;
	AVCodec *codec = avcodec_find_decoder(codecCtx->codec_id);
	if(codec == NULL)
	{
		return;
	}
	//打开解码器
	if(avcodec_open2(codecCtx,codec,NULL) < 0)
	{
		return;
	}
	//解码之前的数据
	AVPacket *packet = (AVPacket *)av_malloc(sizeof(AVPacket));
	//解码之后的数据
	AVFrame *frame = av_frame_alloc();

	//输入的采样格式
	enum AVSampleFormat in_sample_fmt = codecCtx->sample_fmt;
	//输出采样格式16bit PCM
	enum AVSampleFormat out_sample_fmt = AV_SAMPLE_FMT_S16;
	//输入采样率
	int in_sample_rate = codecCtx->sample_rate;
	//输出采样率
	int out_sample_rate = in_sample_rate;
	//声道布局（2个声道，默认立体声stereo）
	uint64_t in_ch_layout = codecCtx->channel_layout;
	//输出的声道布局（立体声）
	uint64_t out_ch_layout = AV_CH_LAYOUT_STEREO;
    //输出的声道个数
    int out_channel_nb = av_get_channel_layout_nb_channels(out_ch_layout);
	//音频重采样
	SwrContext *swrCtx = swr_alloc();
	swr_alloc_set_opts(swrCtx,
		  out_ch_layout,out_sample_fmt,out_sample_rate,
		  in_ch_layout,in_sample_fmt,in_sample_rate,
		  0, NULL);
	swr_init(swrCtx);

    // 获取调用这个c文件的java文件类
	jclass player_class = (*env)->GetObjectClass(env,jthiz);
    if(!player_class){
        return;
    }
	//找到 java代码中的  public AudioTrack createAudioTrack(int sampleRate, int channels) 方法
	jmethodID audio_track_method = (*env)->GetMethodID(env,player_class,"createAudioTrack","(II)Landroid/media/AudioTrack;");
    if(!audio_track_method){
        return;
    }
    // 使用java中对应的方法
	jobject audio_track = (*env)->CallObjectMethod(env,jthiz,audio_track_method,out_sample_rate,out_channel_nb);

	//调用AudioTrack 的 play() 方法
	jclass audio_track_class = (*env)->GetObjectClass(env,audio_track);
	jmethodID audio_track_play_mid = (*env)->GetMethodID(env,audio_track_class,"play","()V");
	(*env)->CallVoidMethod(env,audio_track,audio_track_play_mid);

	//转换格式后的数据
	uint8_t *out_buffer = (uint8_t *)av_malloc(MAX_AUDIO_FRAME_SIZE);

	int got_frame = 0 ;
	//不断读取编码数据
    while (av_read_frame(pFormatCtx, packet) >= 0)
    {
        if (packet->stream_index == audio_stream_idx)
        {
            //音频解码
            int ret = avcodec_decode_audio4(codecCtx, frame, &got_frame, packet);
            if (ret < 0)
            {
                break;
            }
            //解码一帧成功
            if (got_frame > 0)
            {
                //音频格式转换
                swr_convert(swrCtx, &out_buffer, MAX_AUDIO_FRAME_SIZE, (const uint8_t **) frame->data, frame->nb_samples);
                int out_buffer_size = av_samples_get_buffer_size(NULL,
                                                                 out_channel_nb,
                                                                 frame->nb_samples,
                                                                 out_sample_fmt,
                                                                 1);

                jbyteArray audio_sample_array = (*env)->NewByteArray(env, out_buffer_size);
                jbyte *sample_byte_array = (*env)->GetByteArrayElements(env, audio_sample_array,
                                                                        NULL);
                //拷贝缓冲数据
                memcpy(sample_byte_array, out_buffer, (size_t) out_buffer_size);
                //释放数组
                (*env)->ReleaseByteArrayElements(env, audio_sample_array, sample_byte_array, 0);

                //调用AudioTrack 的 获取write(...)方法进行播放
                jmethodID audio_track_write_mid = (*env)->GetMethodID(env, audio_track_class,
                                                                      "write", "([BII)I");
                (*env)->CallIntMethod(env,
                                      audio_track,
                                      audio_track_write_mid,
                                      audio_sample_array,
                                      0,
                                      out_buffer_size);
                //释放局部引用
                (*env)->DeleteLocalRef(env, audio_sample_array);
                usleep(1000 * 16);
            }
        }
        av_free_packet(packet);
    }

	av_frame_free(&frame);
	av_free(out_buffer);
	swr_free(&swrCtx);
	avcodec_close(codecCtx);
	avformat_close_input(&pFormatCtx);
	(*env)->ReleaseStringUTFChars(env,input_jstr,input_cstr);
}


public AudioTrack createAudioTrack(int sampleRate, int channels){
    int audioFormat = AudioFormat.ENCODING_PCM_16BIT;
    int channelConfig;
    if(channels == 1){
        // 单声道
        channelConfig = AudioFormat.CHANNEL_OUT_MONO;
    }else if(channels == 2){
        // 输出声道为双声道立体声
        channelConfig = AudioFormat.CHANNEL_OUT_STEREO;
    }else{
        channelConfig = AudioFormat.CHANNEL_OUT_STEREO;
    }
    // sampleRate  采样率
    int bufferSizeInBytes = AudioTrack.getMinBufferSize(sampleRate, channelConfig, audioFormat);
    return new AudioTrack(AudioManager.STREAM_MUSIC,
            sampleRate, channelConfig, audioFormat,bufferSizeInBytes, AudioTrack.MODE_STREAM);
}
```


## native ffmpeg 实现解码 ， native 层的 opensl 实现播放
```text
//OpenSLES - 对象接口-
SLObjectItf engineObject = NULL;
// OpenSLES - 引擎接口-
SLEngineItf engineEngine;
//输出混音器接口
SLObjectItf outputMixObject = NULL;
// 混音器环境接口
SLEnvironmentalReverbItf outputMixEnvironmentalReverb = NULL;
//缓冲播放器接口
SLObjectItf bqPlayerObject = NULL;
// 播放接口
SLPlayItf bqPlayerPlay;
SLAndroidSimpleBufferQueueItf bqPlayerBufferQueue;
SLEffectSendItf bqPlayerEffectSend;
SLVolumeItf bqPlayerVolume;
//音效设置
const SLEnvironmentalReverbSettings reverbSettings = SL_I3DL2_ENVIRONMENT_PRESET_STONECORRIDOR;
void *buffer;
size_t bufferSize;
uint8_t *outputBuffer;
// 分配PCM数据缓存
size_t outputBufferSize;

//FFmpeg相关
AVPacket packet;
//音频流索引位置
int audioStream;
AVFrame *aFrame;
SwrContext *swr;
AVFormatContext *aFormatCtx;
AVCodecContext *aCodecCtx;
int frame_count = 0;
int createAudioPlayer(int *rate, int *channel, const char *file_name) ;
int releaseAudioPlayer();
int getPCM(void **pcm, size_t *pcmSize) ;

//播放回调方法
void bqPlayerCallback(SLAndroidSimpleBufferQueueItf bufferQueueItf, void *context)
{
    bufferSize = 0;
    getPCM(&buffer, &bufferSize);
    //如果buffer不为空，入待播放队列
    if (NULL != buffer && 0 != bufferSize) {
        SLresult result;
        result = (*bqPlayerBufferQueue)->Enqueue(bqPlayerBufferQueue, buffer, bufferSize);
        if(result < 0){
            LOGE("Enqueue error...");
        } else{
            LOGI("decode frame count=%d", frame_count++);
        }
    }
}

void createEngine()
{
    // 操作结果
    SLresult result;
    //创建引擎
    result = slCreateEngine(&engineObject, 0, NULL, 0, NULL, NULL);
    result = (*engineObject)->Realize(engineObject, SL_BOOLEAN_FALSE);
    //获取引擎接口
    result = (*engineObject)->GetInterface(engineObject, SL_IID_ENGINE, &engineEngine);
    //创建输出混音器
    result = (*engineEngine)->CreateOutputMix(engineEngine, &outputMixObject, 0, 0, 0);
    //关联输出混音器
    result = (*outputMixObject)->Realize(outputMixObject, SL_BOOLEAN_FALSE);
    //获取reverb接口
    result = (*outputMixObject)->GetInterface(outputMixObject,
                                              SL_IID_ENVIRONMENTALREVERB,
                                              &outputMixEnvironmentalReverb);
    if (SL_RESULT_SUCCESS == result)
    {
        result = (*outputMixEnvironmentalReverb)->SetEnvironmentalReverbProperties(
                outputMixEnvironmentalReverb, &reverbSettings);
    }
}

void createBufferQueueAudioPlayer(int rate, int channel, int bitsPerSample)
{
    SLresult result;
    //配置音频源
    SLDataLocator_AndroidSimpleBufferQueue buffer_queue = {SL_DATALOCATOR_ANDROIDSIMPLEBUFFERQUEUE, 2};
    SLDataFormat_PCM format_pcm;
    format_pcm.formatType = SL_DATAFORMAT_PCM;
    format_pcm.numChannels = (SLuint32) channel;
    format_pcm.bitsPerSample = (SLuint32) bitsPerSample;
    format_pcm.samplesPerSec = (SLuint32) (rate * 1000);
    format_pcm.containerSize = 16;
    if (channel == 2)
    {
        format_pcm.channelMask = SL_SPEAKER_FRONT_LEFT | SL_SPEAKER_FRONT_RIGHT;
    } else{
        format_pcm.channelMask = SL_SPEAKER_FRONT_CENTER;
    }
    format_pcm.endianness = SL_BYTEORDER_LITTLEENDIAN;
    SLDataSource audioSrc = {&buffer_queue, &format_pcm};
    //配置音频池
    SLDataLocator_OutputMix loc_outmix = {SL_DATALOCATOR_OUTPUTMIX, outputMixObject};
    SLDataSink audioSnk = {&loc_outmix, NULL};
    //创建音频播放器
    const SLInterfaceID ids[3] = {SL_IID_BUFFERQUEUE, SL_IID_EFFECTSEND, SL_IID_VOLUME};
    const SLboolean req[3] = {SL_BOOLEAN_TRUE, SL_BOOLEAN_TRUE, SL_BOOLEAN_TRUE};
    result = (*engineEngine)->CreateAudioPlayer(engineEngine,
                                                &bqPlayerObject,
                                                &audioSrc,
                                                &audioSnk,
                                                3,
                                                ids,
                                                req);
    //关联播放器
    result = (*bqPlayerObject)->Realize(bqPlayerObject, SL_BOOLEAN_FALSE);
    //获取播放接口
    result = (*bqPlayerObject)->GetInterface(bqPlayerObject, SL_IID_PLAY, &bqPlayerPlay);
    //获取缓冲队列接口
    result = (*bqPlayerObject)->GetInterface(bqPlayerObject, SL_IID_BUFFERQUEUE,
                                             &bqPlayerBufferQueue);
    //注册缓冲队列回调
    result = (*bqPlayerBufferQueue)->RegisterCallback(bqPlayerBufferQueue, bqPlayerCallback, NULL);
    //获取音效接口
    result = (*bqPlayerObject)->GetInterface(bqPlayerObject, SL_IID_EFFECTSEND,
                                             &bqPlayerEffectSend);
    //获取音量接口
    result = (*bqPlayerObject)->GetInterface(bqPlayerObject, SL_IID_VOLUME, &bqPlayerVolume);
    //开始播放音乐
    result = (*bqPlayerPlay)->SetPlayState(bqPlayerPlay, SL_PLAYSTATE_PLAYING);
}

int createAudioPlayer(int *rate, int *channel, const char *file_name)
{
    av_register_all();
    aFormatCtx = avformat_alloc_context();

    if (avformat_open_input(&aFormatCtx, file_name, NULL, NULL) != 0)
    {
        return -1;
    }

    if (avformat_find_stream_info(aFormatCtx, NULL) < 0) {
        return -1;
    }

    for (int i = 0; i < aFormatCtx->nb_streams; i++)
    {
        if (aFormatCtx->streams[i]->codec->codec_type == AVMEDIA_TYPE_AUDIO && audioStream < 0) {
            audioStream = i;
        }
    }
    if (audioStream == -1)
    {
        return -1;
    }
    aCodecCtx = aFormatCtx->streams[audioStream]->codec;
    AVCodec *aCodec = avcodec_find_decoder(aCodecCtx->codec_id);
    if (aCodec==NULL)
    {
        return -1;
    }
    if (avcodec_open2(aCodecCtx, aCodec, NULL) < 0)
    {
        return -1;
    }
    aFrame = av_frame_alloc();

    // 设置格式转换 ,  也可以使用swr_alloc_set_opts(...)设置
    swr = swr_alloc();
    av_opt_set_int(swr, "in_channel_layout",  aCodecCtx->channel_layout, 0);
    av_opt_set_int(swr, "out_channel_layout", aCodecCtx->channel_layout,  0);
    av_opt_set_int(swr, "in_sample_rate",     aCodecCtx->sample_rate, 0);
    av_opt_set_int(swr, "out_sample_rate",    aCodecCtx->sample_rate, 0);
    av_opt_set_sample_fmt(swr, "in_sample_fmt",  aCodecCtx->sample_fmt, 0);
    av_opt_set_sample_fmt(swr, "out_sample_fmt", AV_SAMPLE_FMT_S16,  0);
    swr_init(swr);

    outputBufferSize = 8196;
    outputBuffer = (uint8_t *) malloc(sizeof(uint8_t) * outputBufferSize);
    // 返回sample rate和channels
    *rate = aCodecCtx->sample_rate;
    *channel = aCodecCtx->channels;
    return 0;
}

// 获取PCM数据, 自动回调获取
int getPCM(void **pcm, size_t *pcmSize)
{
    while (av_read_frame(aFormatCtx, &packet) >= 0)
    {
        int frameFinished = 0;
        //音频流
        if (packet.stream_index == audioStream)
        {
            avcodec_decode_audio4(aCodecCtx, aFrame, &frameFinished, &packet);
            //解码完一帧数据
            if (frameFinished)
            {
                // data_size为音频数据所占的字节数
                int data_size = av_samples_get_buffer_size(
                        aFrame->linesize, aCodecCtx->channels,
                        aFrame->nb_samples, aCodecCtx->sample_fmt, 1);

                if (data_size > outputBufferSize)
                {
                    outputBufferSize = (size_t) data_size;
                    outputBuffer = (uint8_t *) realloc(outputBuffer, sizeof(uint8_t) * outputBufferSize);
                }

                // 音频格式转换
                swr_convert(swr, &outputBuffer, aFrame->nb_samples,
                            (uint8_t const **) (aFrame->extended_data),
                            aFrame->nb_samples);

                // 返回pcm数据
                *pcm = outputBuffer;
                *pcmSize = (size_t) data_size;
                return 0;
            }
        }
    }
    return -1;
}

// 释放相关资源
int releaseAudioPlayer()
{
    av_packet_unref(&packet);
    av_free(outputBuffer);
    av_free(aFrame);
    avcodec_close(aCodecCtx);
    avformat_close_input(&aFormatCtx);
    return 0;
}

// 对外播放接口 ，传入 mp3 绝对地址
JNIEXPORT void JNICALL Java_com_frank_ffmpeg_AudioPlayer_playAudio
        (JNIEnv * env, jclass jobject, jstring filePath)
{
    int rate, channel;
    const char *file_name = (*env)->GetStringUTFChars(env, filePath, NULL);
    // 创建音频解码器
    createAudioPlayer(&rate, &channel, file_name);
    // 创建OpenSLES引擎
    createEngine();
    // 创建带有缓冲队列的音频播放器
    createBufferQueueAudioPlayer(rate, channel, SL_PCMSAMPLEFORMAT_FIXED_16);
    // 启动音频播放
    bqPlayerCallback(bqPlayerBufferQueue, NULL);
}

//停止播放，释放相关资源
JNIEXPORT jint JNICALL Java_com_frank_ffmpeg_AudioPlayer_stop
        (JNIEnv * env, jclass jobject) {
    if (bqPlayerObject != NULL) {
        (*bqPlayerObject)->Destroy(bqPlayerObject);
        bqPlayerObject = NULL;
        bqPlayerPlay = NULL;
        bqPlayerBufferQueue = NULL;
        bqPlayerEffectSend = NULL;
        bqPlayerVolume = NULL;
    }

    if (outputMixObject != NULL) {
        (*outputMixObject)->Destroy(outputMixObject);
        outputMixObject = NULL;
        outputMixEnvironmentalReverb = NULL;
    }

    if (engineObject != NULL) {
        (*engineObject)->Destroy(engineObject);
        engineObject = NULL;
        engineEngine = NULL;
    }

    // 释放解码器相关资源
    releaseAudioPlayer();
}
```


## 播放本地MP4
```text
#define MAX_AUDIO_FRAME_SIZE 48000 * 4
#define PACKET_SIZE 50
#define MIN_SLEEP_TIME_US 1000ll
#define AUDIO_TIME_ADJUST_US -200000ll

typedef struct MediaPlayer{
    AVFormatContext* format_context;
    int video_stream_index;
    int audio_stream_index;
    AVCodecContext* video_codec_context;
    AVCodecContext* audio_codec_context;
    AVCodec* video_codec;
    AVCodec* audio_codec;
    ANativeWindow* native_window;
    uint8_t* buffer;
    AVFrame* yuv_frame;
    AVFrame* rgba_frame;
    int video_width;
    int video_height;
    SwrContext* swrContext;
    int out_channel_nb;
    int out_sample_rate;
    enum AVSampleFormat out_sample_fmt;
    jobject audio_track;
    jmethodID audio_track_write_mid;
    uint8_t* audio_buffer;
    AVFrame* audio_frame;
    AVPacketQueue* packets[2];
    pthread_mutex_t mutex;
    pthread_cond_t cond;
    int64_t start_time;
    int64_t audio_clock;
    pthread_t write_thread;
    pthread_t video_thread;
    pthread_t audio_thread;
}MediaPlayer;

typedef struct Decoder{
    MediaPlayer* player;
    int stream_index;
}Decoder;

JavaVM* javaVM;
MediaPlayer* player;


jint JNICALL JNI_OnLoad(JavaVM* vm, void* reserved)
{
    javaVM = vm;
    return JNI_VERSION_1_6;
}

int init_input_format_context(MediaPlayer* player, const char* file_name)
{
    av_register_all();
    player->format_context = avformat_alloc_context();
    if(avformat_open_input(&player->format_context, file_name, NULL, NULL)!=0)
    {
        return -1;
    }
    //查找是否有音频 或 视频信息
    if(avformat_find_stream_info(player->format_context, NULL)<0)
    {
        return -1;
    }
    //寻找音视频流索引位置
    player->video_stream_index = -1;
    player->audio_stream_index = -1;
    for (int i = 0; i < player->format_context->nb_streams; i++)
    {
        if (player->format_context->streams[i]->codec->codec_type == AVMEDIA_TYPE_VIDEO && player->video_stream_index < 0)
        {
            player->video_stream_index = i;
        } else if (player->format_context->streams[i]->codec->codec_type == AVMEDIA_TYPE_AUDIO && player->audio_stream_index < 0) {
            player->audio_stream_index = i;
        }
    }
    if(player->video_stream_index==-1)
    {
        // 没有视频信息
        return -1;
    }
    if(player->audio_stream_index==-1)
    {
       // 没有音频信息
        return -1;
    }
    return 0;
}

//打开音视频解码器
int init_condec_context(MediaPlayer* player)
{
    //获取codec上下文指针
    player->video_codec_context = player->format_context->streams[player->video_stream_index]->codec;
    //寻找视频流的解码器
    player->video_codec = avcodec_find_decoder(player->video_codec_context->codec_id);
    if(player->video_codec == NULL)
    {
        return -1;
    }
    // 打开解码器
    if(avcodec_open2(player->video_codec_context, player->video_codec, NULL) < 0)
    {
        return -1;
    }
    player->audio_codec_context = player->format_context->streams[player->audio_stream_index]->codec;
    player->audio_codec = avcodec_find_decoder(player->audio_codec_context->codec_id);
    if( player->audio_codec == NULL)
    {
        return -1;
    }
    if(avcodec_open2(player->audio_codec_context, player->audio_codec, NULL) < 0)
    {
        return -1;
    }
    // 获取视频宽高
    player->video_width = player->video_codec_context->width;
    player->video_height = player->video_codec_context->height;
    return 0;
}

// 获得 ANativeWindow  surface
void video_player_prepare(MediaPlayer* player, JNIEnv* env, jobject surface)
{
    player->native_window = ANativeWindow_fromSurface(env, surface);
}

//获取当前播放时间
int64_t get_play_time(MediaPlayer* player){
    return (int64_t)(av_gettime() - player->start_time);
}

// 音视频同步
void player_wait_for_frame(MediaPlayer *player, int64_t stream_time)
{
    pthread_mutex_lock(&player->mutex);
    for(;;){
        int64_t current_video_time = get_play_time(player);
        int64_t sleep_time = stream_time - current_video_time;
        if (sleep_time < -300000ll) {
            // 300 ms late
            int64_t new_value = player->start_time - sleep_time;
            player->start_time = new_value;
            pthread_cond_broadcast(&player->cond);
        }

        if (sleep_time <= MIN_SLEEP_TIME_US) {
            // We do not need to wait if time is slower then minimal sleep time
            break;
        }

        if (sleep_time > 500000ll) {
            // if sleep time is bigger then 500ms just sleep this 500ms
            // and check everything again
            sleep_time = 500000ll;
        }
        //等待指定时长
        pthread_cond_timeout_np(&player->cond, &player->mutex,
                                                  (unsigned int) (sleep_time / 1000ll));
    }
    pthread_mutex_unlock(&player->mutex);
}

//视频解码
int decode_video(MediaPlayer* player, AVPacket* packet)
{
    ANativeWindow_setBuffersGeometry(player->native_window,  player->video_width,
                                     player->video_height, WINDOW_FORMAT_RGBA_8888);

    ANativeWindow_Buffer windowBuffer;
    player->yuv_frame = av_frame_alloc();
    player->rgba_frame = av_frame_alloc();
    if(player->rgba_frame == NULL || player->yuv_frame == NULL)
    {
        return -1;
    }

    // buffer中数据用于渲染,且格式为RGBA
    int numBytes=av_image_get_buffer_size(AV_PIX_FMT_RGBA, player->video_width, player->video_height, 1);

    player->buffer = (uint8_t *)av_malloc(numBytes*sizeof(uint8_t));
    av_image_fill_arrays(player->rgba_frame->data,
                         player->rgba_frame->linesize,
                         player->buffer,
                         AV_PIX_FMT_RGBA,
                         player->video_width,
                         player->video_height,
                         1);

    // 由于解码出来的帧格式不是RGBA的,在渲染之前需要进行格式转换
    struct SwsContext *sws_ctx = sws_getContext(
            player->video_width,
            player->video_height,
            player->video_codec_context->pix_fmt,
            player->video_width,
            player->video_height,
            AV_PIX_FMT_RGBA,
            SWS_BILINEAR,
            NULL,
            NULL,
            NULL);

    int frameFinished;
    //解码
    int ret = avcodec_decode_video2(player->video_codec_context, player->yuv_frame, &frameFinished, packet);
    if(ret < 0)
    {
        return -1;
    }
    if (frameFinished) {
        // lock native window
        ANativeWindow_lock(player->native_window, &windowBuffer, 0);
        // 格式转换
        sws_scale(sws_ctx, (uint8_t const * const *)player->yuv_frame->data,
                  player->yuv_frame->linesize, 0, player->video_height,
                  player->rgba_frame->data, player->rgba_frame->linesize);
        // 获取stride
        uint8_t * dst = windowBuffer.bits;
        int dstStride = windowBuffer.stride * 4;
        uint8_t * src = player->rgba_frame->data[0];
        int srcStride = player->rgba_frame->linesize[0];
        // 由于window的stride和帧的stride不同,因此需要逐行复制
        int h;
        for (h = 0; h < player->video_height; h++)
        {
            memcpy(dst + h * dstStride, src + h * srcStride, (size_t) srcStride);
        }

        //计算延迟
        int64_t pts = av_frame_get_best_effort_timestamp(player->yuv_frame);
        AVStream *stream = player->format_context->streams[player->video_stream_index];
        //转换（不同时间基时间转换）
        int64_t time = av_rescale_q(pts, stream->time_base, AV_TIME_BASE_Q);
        //音视频帧同步
        player_wait_for_frame(player, time);
        ANativeWindow_unlockAndPost(player->native_window);
    }
    return 0;
}

//音频解码初始化
void audio_decoder_prepare(MediaPlayer* player)
{
    //frame->16bit 44100 PCM 统一音频采样格式与采样率
    player->swrContext = swr_alloc();
    //输入的采样格式
    enum AVSampleFormat in_sample_fmt = player->audio_codec_context->sample_fmt;
    //输出采样格式16bit PCM
    player->out_sample_fmt = AV_SAMPLE_FMT_S16;
    //输入采样率
    int in_sample_rate = player->audio_codec_context->sample_rate;
    //输出采样率
    player->out_sample_rate = in_sample_rate;
    //声道布局（2个声道，默认立体声stereo）
    uint64_t in_ch_layout = player->audio_codec_context->channel_layout;
    //输出的声道布局（立体声）
    uint64_t out_ch_layout = AV_CH_LAYOUT_STEREO;
    swr_alloc_set_opts(player->swrContext,
                       out_ch_layout, player->out_sample_fmt, player->out_sample_rate,
                       in_ch_layout, in_sample_fmt, in_sample_rate,
                       0, NULL);
    swr_init(player->swrContext);
    //输出的声道个数
    player->out_channel_nb = av_get_channel_layout_nb_channels(out_ch_layout);
}

//音频播放器
void audio_player_prepare(MediaPlayer* player, JNIEnv* env, jclass jthiz)
{
    jclass player_class = (*env)->GetObjectClass(env,jthiz);
    if(!player_class)
    {
       return ;
    }
    // 根据自定义的java方法 createAudioTrack 获取 android 自带的 AudioTrack 对象
    jmethodID audio_track_method = (*env)->GetMethodID(env,player_class,"createAudioTrack","(II)Landroid/media/AudioTrack;");
    if(!audio_track_method)
    {
        return ;
    }
    jobject audio_track = (*env)->CallObjectMethod( env,jthiz,audio_track_method, player->out_sample_rate, player->out_channel_nb);
    //调用 AudioTrack 的play()方法
    jclass audio_track_class = (*env)->GetObjectClass(env, audio_track);
    jmethodID audio_track_play_mid = (*env)->GetMethodID(env,audio_track_class,"play","()V");
    (*env)->CallVoidMethod(env, audio_track, audio_track_play_mid);

    player->audio_track = (*env)->NewGlobalRef(env, audio_track);
    //获取 AudioTrack 的 write()方法
    player->audio_track_write_mid = (*env)->GetMethodID(env,audio_track_class,"write","([BII)I");
    //16bit 44100 PCM 数据
    player->audio_buffer = (uint8_t *)av_malloc(MAX_AUDIO_FRAME_SIZE);
    //解码后的音频数据
    player->audio_frame = av_frame_alloc();
}

//音频解码 + 播放
int decode_audio(MediaPlayer* player, AVPacket* packet)
{
    int got_frame = 0, ret;
    //解码
    ret = avcodec_decode_audio4(player->audio_codec_context, player->audio_frame, &got_frame, packet);
    if(ret < 0)
    {
        return -1;
    }
    //解码一帧成功
    if(got_frame > 0)
    {
        //音频格式转换
        swr_convert(player->swrContext, &player->audio_buffer,  MAX_AUDIO_FRAME_SIZE, (const uint8_t **)player->audio_frame->data, player->audio_frame->nb_samples);
        int out_buffer_size = av_samples_get_buffer_size(NULL,
                                                         player->out_channel_nb,
                                                         player->audio_frame->nb_samples,
                                                         player->out_sample_fmt,
                                                         1);

        //音视频帧同步
        int64_t pts = packet->pts;
        // AV_NOPTS_VALUE  无效的pts 标记
        if (pts != AV_NOPTS_VALUE)
        {
            AVStream *stream = player->format_context->streams[player->audio_stream_index];
            // av_rescale_q  AV_TIME_BASE_Q
            player->audio_clock = av_rescale_q(pts, stream->time_base, AV_TIME_BASE_Q);
            player_wait_for_frame(player, player->audio_clock + AUDIO_TIME_ADJUST_US);
        }

        if(javaVM != NULL)
        {
            JNIEnv * env;
            (*javaVM)->AttachCurrentThread(javaVM, &env, NULL);
            jbyteArray audio_sample_array = (*env)->NewByteArray(env,out_buffer_size);
            jbyte* sample_byte_array = (*env)->GetByteArrayElements(env,audio_sample_array,NULL);
            memcpy(sample_byte_array, player->audio_buffer, (size_t) out_buffer_size);
            (*env)->ReleaseByteArrayElements(env,audio_sample_array,sample_byte_array,0);
            //调用AudioTrack的write方法进行播放
            (*env)->CallIntMethod(env, player->audio_track, player->audio_track_write_mid, audio_sample_array,0,out_buffer_size);
            (*env)->DeleteLocalRef(env,audio_sample_array);
        }
    }
    if(javaVM != NULL)
    {
        (*javaVM)->DetachCurrentThread(javaVM);
    }
    return 0;
}

//初始化队列
void init_queue(MediaPlayer* player, int size)
{
    for (int i = 0; i < 2; ++i)
    {
        AVPacketQueue* queue = queue_init(size);
        player->packets[i] = queue;
    }
}

//释放队列
void delete_queue(MediaPlayer* player){
    int i;
    for (i = 0; i < 2; ++i) {
        queue_free(player->packets[i]);
    }
}

//读取AVPacket线程(生产者) ， 获得解码之前的音频数据+视频数据
void* write_packet_to_queue(void* arg)
{
    MediaPlayer* player = (MediaPlayer*)arg;
    AVPacket packet ;
    AVPacket *pkt = &packet;
    for(;;)
    {
        int ret = av_read_frame(player->format_context, pkt);
        if(ret < 0)
        {
            break;
        }
        if(pkt->stream_index == player->video_stream_index || pkt->stream_index == player->audio_stream_index)
        {
            // 将 每一帧 解码前的 数据 分别存到 音频 和视频的缓冲队列中
            AVPacketQueue *queue = player->packets[pkt->stream_index];
            pthread_mutex_lock(&player->mutex);
            AVPacket* data = queue_push(queue, &player->mutex, &player->cond);
            pthread_mutex_unlock(&player->mutex);
            *data = packet;
        }
    }
}


//根据参数 解码音频 或 视频
void* decode_func(void* arg)
{
    Decoder *decoder_data = (Decoder*)arg;
    MediaPlayer *player = decoder_data->player;
    int stream_index = decoder_data->stream_index;
    AVPacketQueue *queue = player->packets[stream_index];

    for(;;)
    {
        pthread_mutex_lock(&player->mutex);
        AVPacket *packet = (AVPacket*)queue_pop(queue, &player->mutex, &player->cond);
        pthread_mutex_unlock(&player->mutex);

        int ret = 0;
        if(stream_index == player->video_stream_index) {
            // 解码 视频
            ret = decode_video(player, packet);
        } else if(stream_index == player->audio_stream_index)
        {
            // 解码 音频
            ret = decode_audio(player, packet);
        }
        av_packet_unref(packet);
        if(ret < 0)
        {
            break;
        }
    }
}


// 对外接口 ，初始化 播放器
JNIEXPORT jint JNICALL Java_com_frank_ffmpeg_MediaPlayer_setup
        (JNIEnv * env, jclass clazz, jstring filePath, jobject surface)
{

    const char *file_name = (*env)->GetStringUTFChars(env, filePath, JNI_FALSE);
    player = malloc(sizeof(MediaPlayer));
    if(player == NULL)
    {
        return -1;
    }
    //初始化输入格式上下文
    int ret = init_input_format_context(player, file_name);
    if(ret < 0)
    {
        return -1;
    }
    //初始化音视频解码器
    ret = init_condec_context(player);
    if(ret < 0)
    {
        return -1;
    }
    //初始化视频surface
    video_player_prepare( player, env, surface);
    //初始化音频相关参数
    audio_decoder_prepare(player);
    //初始化音频播放器
    audio_player_prepare(player, env,  clazz);
    //初始化音视频packet队列
    init_queue(player, PACKET_SIZE);
    return 0;
}

// 对外接口 ， 播放音视频
JNIEXPORT jint JNICALL Java_com_frank_ffmpeg_MediaPlayer_play (JNIEnv * env, jclass clazz)
{
    pthread_mutex_init(&player->mutex, NULL);
    pthread_cond_init(&player->cond, NULL);

    // 获得解码前的 音频数据 和视频数据 ， 子线程
    pthread_create(&player->write_thread, NULL, write_packet_to_queue, (void*)player);
    sleep(1);
    player->start_time = 0;

    //解码视频 ， 子线程
    Decoder data1 = {player, player->video_stream_index} ;
    Decoder *decoder_data1 = &data1;
    pthread_create(&player->video_thread, NULL, decode_func, (void*)decoder_data1);

    // 解码音频 ， 子线程
    Decoder data2 = {player, player->audio_stream_index} ;
    Decoder *decoder_data2 = &data2;
    pthread_create(&player->audio_thread,NULL,decode_func,(void*)decoder_data2);

    pthread_join(player->write_thread, NULL);
    pthread_join(player->video_thread, NULL);
    pthread_join(player->audio_thread, NULL);

    return 0;
}

// 释放资源
JNIEXPORT void JNICALL Java_com_frank_ffmpeg_MediaPlayer_release
        (JNIEnv * env, jclass clazz)
{
    //释放内存以及关闭文件
    free(player->audio_track);
    free(player->audio_track_write_mid);
    av_free(player->buffer);
    av_free(player->rgba_frame);
    av_free(player->yuv_frame);
    av_free(player->audio_buffer);
    av_free(player->audio_frame);
    avcodec_close(player->video_codec_context);
    avcodec_close(player->audio_codec_context);
    avformat_close_input(&player->format_context);
    ANativeWindow_release(player->native_window);
    delete_queue(player);
    pthread_cond_destroy(&player->cond);
    pthread_mutex_destroy(&player->mutex);
    free(player);
    (*javaVM)->DestroyJavaVM(javaVM);
}

```

```text 
public AudioTrack createAudioTrack(int sampleRate, int channels){
    int audioFormat = AudioFormat.ENCODING_PCM_16BIT;
    int channelConfig;
    if(channels == 1){
        channelConfig = android.media.AudioFormat.CHANNEL_OUT_MONO;
    }else if(channels == 2){
        channelConfig = android.media.AudioFormat.CHANNEL_OUT_STEREO;
    }else{
        channelConfig = android.media.AudioFormat.CHANNEL_OUT_STEREO;
    }

    //  返回音轨所需的估计最小缓冲区大小    
    int bufferSizeInBytes = AudioTrack.getMinBufferSize(sampleRate, channelConfig, audioFormat);

    return new AudioTrack(AudioManager.STREAM_MUSIC, sampleRate, channelConfig, audioFormat,
            bufferSizeInBytes, AudioTrack.MODE_STREAM);
}
```

## ffmpeg软解rtsp简单直播
[所需so](https://download.csdn.net/user/dengpanwen/uploads)

```text
include <jni.h>
include <string>
include <android/bitmap.h>
include <android/native_window.h>
include <android/native_window_jni.h>

extern "C" {
include <libavcodec/avcodec.h>
include <libswscale/swscale.h>
include <libavformat/avformat.h>
include <libavutil/avutil.h>
include <libavutil/frame.h>
include <libavdevice/avdevice.h>
include <libavfilter/avfilter.h>
include "libswresample/swresample.h"
include "libavutil/opt.h"
include "libavutil/imgutils.h"
}

static AVPacket *pPacket;
static AVFrame *pAvFrame, *pFrameBGR;
static AVCodecContext *pCodecCtx;
struct SwsContext *pImgConvertCtx;
static AVFormatContext *pFormatCtx;
ANativeWindow* nativeWindow;
ANativeWindow_Buffer windowBuffer;
uint8_t *v_out_buffer;
bool stop;

extern "C"
JNIEXPORT jint JNICALL
Java_com_nazhi_testlive555_FfmpegUtils_openVideo(JNIEnv *env, jclass type, jstring url,
                                                 jobject surface) {
    stop = false;
    // 版本兼容
    if LIBAVCODEC_VERSION_INT < AV_VERSION_INT(55, 28, 1)
    define av_frame_alloc  avcodec_alloc_frame
    endif

    pAvFrame = av_frame_alloc();
    pFrameBGR = av_frame_alloc();

    char input_str[500]={0};
    // 初始化rtsp地址
    sprintf(input_str, "%s", env->GetStringUTFChars(url, NULL));
    //绑定surface 和 ANativeWindow
    nativeWindow = ANativeWindow_fromSurface(env, surface);
    if (0 == nativeWindow){
        return -1;
    }

    //注册编解码器
    avcodec_register_all();
    //注册所有组件
    av_register_all();
    // 初始化网络库
    avformat_network_init();
    // 注册设备
    avdevice_register_all();

    pFormatCtx = avformat_alloc_context();
    // 打开rtsp流
    if (avformat_open_input(&pFormatCtx, input_str, NULL, NULL) < 0)
    {
        return 1;
    }
    // 获取音频信息
    avformat_find_stream_info(pFormatCtx, NULL);

    int videoIndex = -1;
    //遍历找到的视音频流
    for (unsigned int i = 0; i < pFormatCtx->nb_streams; i++)
    {
        // 找到视频流
        if (pFormatCtx->streams[i]->codec->codec_type == AVMEDIA_TYPE_VIDEO) {
            videoIndex = i;
            break;
        }
    }

    // 获得解码需要的相关信息
    pCodecCtx = pFormatCtx->streams[videoIndex]->codec;

    // 获得 编码器相关信息
    AVCodec *pCodec = avcodec_find_decoder(pCodecCtx->codec_id);
    //为各种结构体分配内存 和一些必要的检查
    avcodec_open2(pCodecCtx, pCodec, NULL);

    int width = pCodecCtx->width;
    int height = pCodecCtx->height;

    // 计算缓冲区填充所需的大小
    int numBytes = av_image_get_buffer_size(AV_PIX_FMT_RGBA, width, height, 1);
    v_out_buffer = (uint8_t *)av_malloc(numBytes*sizeof(uint8_t));

    // 给像素数据分配空间
    av_image_fill_arrays(pFrameBGR->data, pFrameBGR->linesize, v_out_buffer, AV_PIX_FMT_RGBA, width, height, 1);

    //SwsContext 主要用于视频图像的转换 ，sws_getContext初始化
    pImgConvertCtx = sws_getContext(
            pCodecCtx->width,             //原始宽度
            pCodecCtx->height,            //原始高度
            pCodecCtx->pix_fmt,           //原始格式
            pCodecCtx->width,             //目标宽度
            pCodecCtx->height,            //目标高度
            AV_PIX_FMT_RGBA,              //目标格式
            SWS_BICUBIC,                  //算法类型
            NULL,
            NULL,
            NULL);

    // 设置 ANativeWindow 的缓存大小 ,返回值 < 0 表示失败
    if ( ANativeWindow_setBuffersGeometry(nativeWindow,width,height,WINDOW_FORMAT_RGBA_8888) <0 ){
        ANativeWindow_release(nativeWindow);
        return -1;
    }


    // 给 AVPacket 分配内存
    pPacket = (AVPacket*)av_malloc(sizeof(AVPacket));

    while (!stop) {
        // 获得一帧视频的压缩数据
        if (av_read_frame(pFormatCtx, pPacket) >= 0) {
            if ((pPacket)->stream_index != videoIndex) {
                continue;
            }

            int gotPicCount = 0;
            //解码 ,  解码失败 gotPicCount 返回值为0
            avcodec_decode_video2(pCodecCtx, pAvFrame, &gotPicCount, pPacket);
            if (gotPicCount != 0) {
                // 转换像素
                sws_scale(
                        pImgConvertCtx,
                        (const uint8_t *const *) pAvFrame->data,
                        pAvFrame->linesize,
                        0,
                        pCodecCtx->height,
                        pFrameBGR->data,
                        pFrameBGR->linesize);

                // 锁定 ANativeWindow , 返回值 小于0 代表失败
                if (ANativeWindow_lock(nativeWindow, &windowBuffer, NULL) >= 0)
                {
                    uint8_t *dst = (uint8_t *) windowBuffer.bits;
                    for (int h = 0; h < height; h++)
                    {
                        // 将数据拷贝到 ANativeWindow 以便解码、显示
                        memcpy(dst + h * windowBuffer.stride * 4,
                               v_out_buffer + h * pFrameBGR->linesize[0],
                               pFrameBGR->linesize[0]);
                    }
                    // 释放锁定 ANativeWindow
                    ANativeWindow_unlockAndPost(nativeWindow);
                }
            }
        }
        // 重置 AVPacket
        av_packet_unref(pPacket);
    }
    // 释放 SwsContext
    sws_freeContext(pImgConvertCtx);
    //释放
    av_free(pPacket);
    av_free(pFrameBGR);
    // 关闭 AVCodecContext
    avcodec_close(pCodecCtx);
    // 关闭 AVFormatContext
    avformat_close_input(&pFormatCtx);
    return 1;
}


extern "C"
JNIEXPORT void JNICALL
Java_com_nazhi_testlive555_FfmpegUtils_stop(JNIEnv *env, jclass type) {
    stop = true;
}
```
